"""
Template generation for performance E2E tests.

Generates pytest tests for validating server performance:
- Concurrent tool calls
- Load testing with multiple sessions
- Memory leak detection (event store cleanup)
- Startup time benchmarks
"""

from ...models import ApiMetadata, ModuleSpec, SecurityConfig


def generate_performance_tests(
    api_metadata: ApiMetadata,
    security_config: SecurityConfig,
    modules: dict[str, ModuleSpec],
) -> str:
    """
    Generate performance E2E tests.

    Args:
        api_metadata: API metadata
        security_config: Security configuration
        modules: Generated server modules

    Returns:
        Complete test file content
    """

    total_tools = sum(spec.tool_count for spec in modules.values())

    code = f'''"""
Generated Performance E2E Tests for {api_metadata.title}

Performance and scalability tests:
- Concurrent tool calls
- Multiple session handling
- Memory leak detection
- Startup time benchmarks

Generated by mcp_generator - DO NOT EDIT MANUALLY

Note: These tests are marked as slow and can be skipped with: pytest -m "not slow"
"""

import pytest
import httpx
import os
import json
import asyncio
import time
from pathlib import Path


pytestmark = pytest.mark.slow  # Mark all tests in this module as slow


@pytest.fixture
def mcp_server_url():
    """MCP Server URL."""
    return os.getenv("MCP_SERVER_URL", "http://localhost:8000/mcp")


@pytest.fixture
async def mcp_session(mcp_server_url):
    """Create an initialized MCP session."""
    async with httpx.AsyncClient(timeout=10.0) as client:
        response = await client.post(
            mcp_server_url,
            json={{
                "jsonrpc": "2.0",
                "id": "init",
                "method": "initialize",
                "params": {{
                    "protocolVersion": "2025-03-26",
                    "capabilities": {{}},
                    "clientInfo": {{"name": "perf-test", "version": "1.0"}}
                }}
            }},
            headers={{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
        )

        session_id = response.headers.get("mcp-session-id")

        # Send initialized notification to complete handshake
        headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
        if session_id:
            headers["mcp-session-id"] = session_id

        await client.post(
            mcp_server_url,
            json={{
                "jsonrpc": "2.0",
                "method": "notifications/initialized"
            }},
            headers=headers
        )

        yield client, mcp_server_url, session_id


class TestConcurrency:
    """Test concurrent request handling."""

    @pytest.mark.asyncio
    async def test_concurrent_tool_list_requests(self, mcp_session):
        """Test server handles multiple concurrent tools/list requests."""
        client, url, session_id = mcp_session

        num_requests = 10
        headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
        if session_id:
            headers["mcp-session-id"] = session_id

        async def make_request(request_id):
            response = await client.post(
                url,
                json={{
                    "jsonrpc": "2.0",
                    "id": f"concurrent-{{request_id}}",
                    "method": "tools/list",
                    "params": {{}}
                }},
                headers=headers
            )

            # Parse SSE or JSON
            if response.status_code == 200:
                if response.headers.get("content-type", "").startswith("text/event-stream"):
                    data = None
                    for line in response.text.split('\\n'):
                        if line.startswith('data: '):
                            data = json.loads(line[6:])
                            break
                    return response.status_code, data if data else {{}}
                else:
                    try:
                        return response.status_code, response.json()
                    except Exception:
                        return response.status_code, {{}}
            else:
                return response.status_code, {{}}

        start_time = time.time()
        tasks = [make_request(i) for i in range(num_requests)]
        results = await asyncio.gather(*tasks)
        elapsed = time.time() - start_time

        # All requests should succeed
        success_count = sum(1 for status, _ in results if status == 200)
        assert success_count == num_requests

        # All should return same tool count
        tool_counts = [len(data.get("result", {{}}).get("tools", [])) for _, data in results]
        assert all(count == {total_tools} for count in tool_counts)

        throughput = num_requests / elapsed
        print(f"\\n✓ Concurrent requests: {{num_requests}} requests in {{elapsed:.2f}}s")
        print(f"  Throughput: {{throughput:.1f}} req/s")
        print(f"  Avg latency: {{(elapsed/num_requests)*1000:.1f}}ms")

    @pytest.mark.asyncio
    async def test_parallel_sessions(self, mcp_server_url):
        """Test server handles multiple parallel sessions."""
        num_sessions = 5

        async def create_session_and_list_tools(session_num):
            async with httpx.AsyncClient(timeout=10.0) as client:
                # Initialize session
                init_response = await client.post(
                    mcp_server_url,
                    json={{
                        "jsonrpc": "2.0",
                        "id": f"init-{{session_num}}",
                        "method": "initialize",
                        "params": {{
                            "protocolVersion": "2025-03-26",
                            "capabilities": {{}},
                            "clientInfo": {{"name": f"session-{{session_num}}", "version": "1.0"}}
                        }}
                    }},
                    headers={{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
                )

                session_id = init_response.headers.get("mcp-session-id")

                # Send initialized notification to complete handshake
                headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
                if session_id:
                    headers["mcp-session-id"] = session_id

                await client.post(
                    mcp_server_url,
                    json={{
                        "jsonrpc": "2.0",
                        "method": "notifications/initialized"
                    }},
                    headers=headers
                )

                # List tools
                headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
                if session_id:
                    headers["mcp-session-id"] = session_id

                tools_response = await client.post(
                    mcp_server_url,
                    json={{
                        "jsonrpc": "2.0",
                        "id": f"tools-{{session_num}}",
                        "method": "tools/list",
                        "params": {{}}
                    }},
                    headers=headers
                )

                # Parse SSE or JSON
                if tools_response.headers.get("content-type", "").startswith("text/event-stream"):
                    data = None
                    for line in tools_response.text.split('\\n'):
                        if line.startswith('data: '):
                            data = json.loads(line[6:])
                            break
                else:
                    data = tools_response.json()

                return tools_response.status_code, len(data["result"]["tools"])

        start_time = time.time()
        tasks = [create_session_and_list_tools(i) for i in range(num_sessions)]
        results = await asyncio.gather(*tasks)
        elapsed = time.time() - start_time

        # All sessions should succeed
        success_count = sum(1 for status, _ in results if status == 200)
        assert success_count == num_sessions

        # All should see same tools
        tool_counts = [count for _, count in results]
        assert all(count == {total_tools} for count in tool_counts)

        print(f"\\n✓ Parallel sessions: {{num_sessions}} sessions in {{elapsed:.2f}}s")
        print(f"  Avg per session: {{(elapsed/num_sessions)*1000:.1f}}ms")


class TestLoadHandling:
    """Test server behavior under load."""

    @pytest.mark.asyncio
    async def test_sustained_request_load(self, mcp_session):
        """Test server handles sustained request load."""
        client, url, session_id = mcp_session

        duration_seconds = 10
        requests_per_second = 5
        total_requests = duration_seconds * requests_per_second

        headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
        if session_id:
            headers["mcp-session-id"] = session_id

        results = []
        start_time = time.time()

        for i in range(total_requests):
            request_start = time.time()

            try:
                response = await client.post(
                    url,
                    json={{
                        "jsonrpc": "2.0",
                        "id": f"load-{{i}}",
                        "method": "tools/list",
                        "params": {{}}
                    }},
                    headers=headers
                )
                results.append({{"status": response.status_code, "latency": time.time() - request_start}})
            except Exception as e:
                results.append({{"status": "error", "error": str(e), "latency": time.time() - request_start}})

            # Rate limiting
            elapsed = time.time() - start_time
            expected_elapsed = (i + 1) / requests_per_second
            if elapsed < expected_elapsed:
                await asyncio.sleep(expected_elapsed - elapsed)

        elapsed = time.time() - start_time

        # Calculate stats
        successful = [r for r in results if r.get("status") == 200]
        success_rate = len(successful) / len(results) * 100
        latencies = [r["latency"] for r in successful]
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        max_latency = max(latencies) if latencies else 0

        # Server should handle sustained load well
        assert success_rate >= 95, f"Success rate too low: {{success_rate:.1f}}%"

        print(f"\\n✓ Sustained load test: {{total_requests}} requests over {{elapsed:.1f}}s")
        print(f"  Success rate: {{success_rate:.1f}}%")
        print(f"  Avg latency: {{avg_latency*1000:.1f}}ms")
        print(f"  Max latency: {{max_latency*1000:.1f}}ms")


class TestMemoryBehavior:
    """Test memory and resource management."""

    @pytest.mark.asyncio
    async def test_session_cleanup(self, mcp_server_url):
        """Test that sessions are cleaned up properly."""
        # Create and destroy multiple sessions
        num_sessions = 20

        for i in range(num_sessions):
            async with httpx.AsyncClient(timeout=10.0) as client:
                # Initialize
                init_response = await client.post(
                    mcp_server_url,
                    json={{
                        "jsonrpc": "2.0",
                        "id": f"init-{{i}}",
                        "method": "initialize",
                        "params": {{
                            "protocolVersion": "2025-03-26",
                            "capabilities": {{}},
                            "clientInfo": {{"name": f"cleanup-test-{{i}}", "version": "1.0"}}
                        }}
                    }},
                    headers={{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
                )

                session_id = init_response.headers.get("mcp-session-id")
                headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
                if session_id:
                    headers["mcp-session-id"] = session_id

                # Send initialized notification to complete handshake
                await client.post(
                    mcp_server_url,
                    json={{
                        "jsonrpc": "2.0",
                        "method": "notifications/initialized"
                    }},
                    headers=headers
                )
                # Client closes, session should be cleaned up

        # After all sessions closed, server should still be responsive
        async with httpx.AsyncClient(timeout=10.0) as client:
            #  Initialize first
            init_response = await client.post(
                mcp_server_url,
                json={{
                    "jsonrpc": "2.0",
                    "id": "init",
                    "method": "initialize",
                    "params": {{
                        "protocolVersion": "2025-03-26",
                        "capabilities": {{}},
                        "clientInfo": {{"name": "final-check", "version": "1.0"}}
                    }}
                }},
                headers={{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
            )

            session_id = init_response.headers.get("mcp-session-id")
            headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
            if session_id:
                headers["mcp-session-id"] = session_id

            # Send initialized notification to complete handshake
            await client.post(
                mcp_server_url,
                json={{
                    "jsonrpc": "2.0",
                    "method": "notifications/initialized"
                }},
                headers=headers
            )

            response = await client.post(
                mcp_server_url,
                json={{
                    "jsonrpc": "2.0",
                    "id": "final-check",
                    "method": "tools/list",
                    "params": {{}}
                }},
                headers=headers
            )
            assert response.status_code == 200

        print(f"\\n✓ Session cleanup: {{num_sessions}} sessions created and cleaned up")
        print("  Server remains responsive after cleanup")


class TestStartupPerformance:
    """Test server startup and request latency."""

    @pytest.mark.asyncio
    async def test_first_request_latency(self, mcp_server_url):
        """Test latency of first request to server."""
        async with httpx.AsyncClient(timeout=30.0) as client:
            start = time.time()
            response = await client.post(
                mcp_server_url,
                json={{
                    "jsonrpc": "2.0",
                    "id": "latency-test",
                    "method": "initialize",
                    "params": {{
                        "protocolVersion": "2025-03-26",
                        "capabilities": {{}},
                        "clientInfo": {{"name": "latency-test", "version": "1.0"}}
                    }}
                }},
                headers={{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
            )
            elapsed = time.time() - start

            assert response.status_code == 200

            # First request should complete in reasonable time
            print(f"\\n✓ Cold start latency: {{elapsed*1000:.1f}}ms")


class TestResponseConsistency:
    """Test that responses remain consistent under load."""

    @pytest.mark.asyncio
    async def test_tool_list_consistency(self, mcp_session):
        """Verify tools/list returns consistent results across many requests."""
        client, url, session_id = mcp_session

        num_requests = 50
        headers = {{"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}}
        if session_id:
            headers["mcp-session-id"] = session_id

        # Collect all responses
        responses = []
        for i in range(num_requests):
            response = await client.post(
                url,
                json={{
                    "jsonrpc": "2.0",
                    "id": f"consistency-{{i}}",
                    "method": "tools/list",
                    "params": {{}}
                }},
                headers=headers
            )

            # Parse SSE or JSON
            if response.headers.get("content-type", "").startswith("text/event-stream"):
                data = None
                for line in response.text.split('\\n'):
                    if line.startswith('data: '):
                        data = json.loads(line[6:])
                        break
            else:
                data = response.json()

            tool_names = sorted([t["name"] for t in data["result"]["tools"]])
            responses.append(tool_names)

        # All responses should be identical
        first_response = responses[0]
        assert all(r == first_response for r in responses)

        print(f"\\n✓ Consistency: {{num_requests}} requests returned identical tool lists")
        print(f"  {{len(first_response)}} tools per response")


# Summary
if __name__ == "__main__":
    print("""
    Performance E2E Tests for {api_metadata.title}
    {"=" * 60}

    Tests:
    ✓ Concurrent request handling
    ✓ Parallel session management
    ✓ Sustained load behavior
    ✓ Session cleanup and memory management
    ✓ Startup performance (import time, cold start)
    ✓ Response consistency under load

    Run tests:
        pytest test_e2e_performance_generated.py -v

    Skip slow tests:
        pytest -m "not slow"

    Note: Performance tests may take several minutes to complete
    """)
'''

    return code
